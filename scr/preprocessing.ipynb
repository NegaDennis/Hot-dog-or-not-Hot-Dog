{"cells":[{"cell_type":"code","source":["# src/preprocessing_image\n","\"\"\"\n","Preprocess image data to prepare for training image recognition models.\n","\n","Function list:\n","-------\n","1. preprocess_image: Load images from multiple folders and assign corresponding labels.\n","\"\"\"\n","import os\n","import tensorflow as tf\n","import numpy as np\n","\n","# pulling variables from config\n","import json\n","\n","with open('config.json') as f:\n","    cfg = json.load(f)\n","\n","img_rows = cfg[\"data_parameters\"][\"img_rows\"]\n","img_cols = cfg[\"data_parameters\"][\"img_cols\"]\n","\n","def preprocess_image(paths_and_labels, image_size=(img_rows,img_cols)):\n","    \"\"\"\n","    Load images from multiple folders and assign corresponding labels.\n","\n","    Parameters\n","    ----------\n","    paths_and_labels : list of tuples\n","        Each tuple = (folder_path, label_string)\n","    image_size : tuple\n","        Resize target (height, width)\n","\n","    Returns\n","    -------\n","    data : list of (image_tensor, label_string)\n","\n","    Example usage:\n","    -------\n","    data_folder = [\n","    (train_hot_dog_path, \"hot_dog\"),\n","    (train_not_hot_dog_path, \"not_hot_dog\")\n","    ]\n","    train_data = preprocess_image(train_folder,image_size= (50,50))\n","    \"\"\"\n","    data = []\n","    for folder_path, label in paths_and_labels:\n","        for file in os.listdir(folder_path):\n","            if file.lower().endswith(('.jpeg', '.jpg')):  # case-insensitive\n","                img_path = os.path.join(folder_path, file)\n","                img = tf.io.read_file(img_path)\n","                img = tf.image.decode_jpeg(img, channels=3)\n","                img = tf.image.resize(img, image_size)\n","                data.append((img, label))\n","    return data\n","\n","def image_to_array(train_data:list,test_data:list):\n","  \"\"\"\n","  convert image data into arrays\n","\n","  Parameters\n","  ---------\n","    train_data (tensor): list carrying training data (output of preprocess_image)\n","    test_data (tensor): list carrying testing data (output of preprocess_image)\n","\n","  Return\n","  ------\n","  Dict of arrays of x_train, y_train, x_test, y_test\n","  \"\"\"\n","\n","  # Extract the image data and labels from the training data\n","  x_train, y_train = zip(*train_data)\n","\n","  # Extract the image data and labels from the testing data\n","  x_test, y_test = zip(*test_data)\n","\n","  ## Convert the image data and labels into NumPy arrays\n","  x_train = np.array(x_train)\n","  y_train = np.array(y_train)\n","  x_test = np.array(x_test)\n","  y_test = np.array(y_test)\n","\n","  return {'x_train':x_train,\n","          'y_train':y_train,\n","          'x_test':x_test,\n","          'y_test':y_test}\n","\n","def image_data_normalizer(x_train,x_test,scale_type):\n","  \"\"\"\n","  normalize (rescale) image data from arrays to prepare for model training\n","\n","  Parameters\n","  ---------\n","  x_train: training data in form of arrays (output of image_to_array)\n","  x_test: testing data in form of arrays (output of image_to_array)\n","  scale_type: method of scaling (options: \"0-1\" and \"-1-+1\")\n","\n","  Return\n","  -------\n","  Normalized arrays\n","  \"\"\"\n","  # change integers to 32-bit floating point numbers\n","  x_train = x_train.astype('float32')\n","  x_test = x_test.astype('float32')\n","\n","  # normalize\n","  if scale_type == \"0-1\":\n","    x_train /= 255\n","    x_test /= 255\n","  elif scale_type == \"-1-+1\":\n","    x_train = (x_train - 127.5)/127.5\n","  else:\n","    print(\"unregconized scale type\")\n","\n","  return {'x_train':x_train,\n","          'x_test': x_test}\n","\n"],"metadata":{"id":"ukoVzxj4Gkac"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":0}